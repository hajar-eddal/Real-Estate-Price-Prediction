{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP3_MAPI3_Sujet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidBert/TP-MAPI3/blob/master/TP3_MAPI3_Sujet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GPonu3KYEus",
        "colab_type": "text"
      },
      "source": [
        "Dans ce TP nous allons voir une famille particulière de réseaux de neurones: les auto-encoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRknvg4JYPZq",
        "colab_type": "text"
      },
      "source": [
        "## Auto-encoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzStzfuqWBct",
        "colab_type": "text"
      },
      "source": [
        "Pour ce premier exemple sur les auto-encodeurs nous utiliserons le jeu de donnée MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C913wA4ZX_HP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "((x_train, y_train), (x_test, y_test)) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCj8rBXb0kLr",
        "colab_type": "text"
      },
      "source": [
        "Les auto-encodeurs sont des réseaux de neurones utilisés le plus souvent pour apprendre de façon non-supervisée ou faiblement supervisée une représentation (features/encodages) d'un jeu de données.  \n",
        "Les auto-encodeurs sont généralement constitués de deux éléments:\n",
        "* Un encodeur chargé de réprésenter les données dans un espace le plus souvent de dimension réduite\n",
        "* Un décodeur capable à partir d'une donnée encodée de reconstruire la donnée initiale\n",
        "![Source wikipedia](https://upload.wikimedia.org/wikipedia/commons/2/28/Autoencoder_structure.png)\n",
        "\n",
        "\n",
        "Le code suivant instancie un décodeur.  \n",
        "Nous avions l'habitude de construire des réseaux de neurones à l'aide de la classe ```Sequential``` de Keras.  Nous allons cette fois-ci utiliser la methode fonctionnelle en important la clase ```Model``` de Keras.  \n",
        "Cette méthode offre un peu plus de souplesse qu'avec le sequential, elle permet notamment de définir un modèle comme une composition de fonctions/couches.  \n",
        "Définissons le modèle de notre encodeur de cette manière.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDMxD4qe8cFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# On commence par définir une couche d'entrées\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "# On definit ensuite les couches suivantes à la manière d'un graph: couche = TypeDeCouche(paramètres_de_la_couche)(CouchePrécédente)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# On définit alors le model à partir de sa couche d'entrée et sa couche de sortie\n",
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "679Iu4Ek_hAD",
        "colab_type": "text"
      },
      "source": [
        "Regardons la dimension de la sortie de notre encodeur:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3912fkb-3GX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(encoder.predict(x_train[:1]).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwdaIREi_qi0",
        "colab_type": "text"
      },
      "source": [
        "Vous allez maintenant coder vous même le décodeur en utilisant l'API Model de Keras.  \n",
        "Nous utiliserons une nouvelle couche proposée dans l'API de Keras, la couche [UpSampling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D) permettant d'augmenter la taille d'un tenseur en répétant ses lignes et ses colonnes.  \n",
        "Le décodeur sera composé des couches suivantes:\n",
        "* Une couche d'inputs faite pour recevoir des tenseurs de la dimension des encodages générés par l'encodeur\n",
        "* Une couche Conv2D 8 filtres, kernel (3,3) activation ReLU et padding=same\n",
        "* Une couche UpSampling2D((2,2))\n",
        "* Une couche Conv2D 8 filtres, kernel (3,3) activation ReLU et padding=same\n",
        "* Une couche UpSampling2D((2,2))\n",
        "* Une couche Conv2D 16 filtres, kernel (3,3) activation ReLU\n",
        "* Une couche UpSampling2D((2,2))\n",
        "* Une couche Conv2D 1 filtre, kernel (3,3) activation Sigmoid et padding=same  \n",
        "\n",
        "La couche de sigmoïde permettra d'obtenir des sorties comprises entre 0 et 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXRKa4JrBVfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import UpSampling2D\n",
        "\n",
        "input_dec = Input(shape=(...))\n",
        "...\n",
        "...\n",
        "decoded = ...\n",
        "\n",
        "decoder = Model(input_dec, decoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxaILz_2KwtG",
        "colab_type": "text"
      },
      "source": [
        "Vérifiez que la sortie de votre décodeur est bien de la forme (_, 28, 28, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmoHX-D0XP9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = encoder.predict(x_train[:1])\n",
        "decoder.predict(y).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7hsfIH5MZmY",
        "colab_type": "text"
      },
      "source": [
        "Nous pouvons maintenant créer un seul model à partir des deux précédents toujours en utilisant Model de Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRdixfNZLCjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auto_encoder = Model(inputs=encoder.input, outputs=decoder(encoder.output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl6GQiMmM0Gz",
        "colab_type": "text"
      },
      "source": [
        "Vérifiez que les deux models sont bien reliés.  \n",
        "Vous devez obtenir une image ne contenant que du bruit. C'est normal nous n'avons rien entrainé pour le moment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZQ7Za9oM6pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(auto_encoder.predict(x_train[:1]).reshape(28, 28), cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7jplGXxNdbW",
        "colab_type": "text"
      },
      "source": [
        "Entrainons maintenant le modèle entier.  \n",
        "Les images étant des pixels prennant la valeur 1 ou 0 nous utiliserons la binary_crossentropy de Keras qui sera appliquée sur chacun des pixels de l'image de sortie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dl9xel8N1LV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auto_encoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "auto_encoder.fit(x_train, x_train, epochs=25, batch_size=128, shuffle=True, validation_data=(x_test, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgGF9UaPOOEe",
        "colab_type": "text"
      },
      "source": [
        "Nous avons entrainé le model auto-encoder, composé lui même de deux sous-models. \n",
        "L'encodeur encode donc les images dans des tenseurs de dimension (4,4,8).  \n",
        "A partir de ces encodages le décodeur est capable de reconstituer l'image de départ.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N14t4MSuf3xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_test = encoder.predict(x_test)\n",
        "y_pred = decoder.predict(z_test)\n",
        "print(f'z_test: {z_test.shape}')\n",
        "print(f'y_pred: {y_pred.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwFRCsXXPaqM",
        "colab_type": "text"
      },
      "source": [
        "Le code suivant nous permet de visualiser le résultat de notre apprentissage sur quelques exemples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9JSOxdygSUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(10):\n",
        "    ax = plt.subplot(2, 10, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    ax = plt.subplot(2, 10, i + 11)\n",
        "    plt.imshow(y_pred[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gomHP5AQYDv",
        "colab_type": "text"
      },
      "source": [
        "## Denoising auto-encoder\n",
        "Nous allons maintenant utiliser des auto-encodeurs pour débruiter des images.  \n",
        "Commençons pour cela par générer des images bruitées.  \n",
        "Utilisez la fonction [random.normal](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.normal.html) de numpy pour rajouter un bruit gaussien sur une copie de x_train et de x_test. Utilisez un bruit centré avec un ecart type de 0.5.  \n",
        "Afin que les images bruitées soient toujours comprises entre 0 et 1 utilisez la fonction [clip](https://docs.scipy.org/doc/numpy/reference/generated/numpy.clip.html) de numpy toujours pour caper les données bruitées que vous venez de générer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gOMsZ8dgVud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_noisy = x_train + ...\n",
        "x_test_noisy = x_test + ... \n",
        "# n'oubliez pas de clipper les valeurs obtenues\n",
        "x_train_noisy = ...\n",
        "x_test_noisy = ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwG8OP1nl_Ut",
        "colab_type": "text"
      },
      "source": [
        "Verifiez vos images perturbées en en affichant quelques unes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrgibF7wmHG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(10):\n",
        "    ax = plt.subplot(1, 10, i + 1)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd0KEQtRdJx-",
        "colab_type": "text"
      },
      "source": [
        "Entrainez votre auto-encodeur à débruiter les images perturbées que vous venez de générer. (x: les images bruitées, target: les images non-bruitées)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMBma_pqjJWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjR0wYQuddwO",
        "colab_type": "text"
      },
      "source": [
        "Affichez le résultat de votre apprentissage en affichant quelques images bruitées et leur déébruitage par l'auto encodeur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qh99Nqbng10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_imgs = auto_encoder.predict(x_test_noisy)\n",
        "\n",
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W7x5KT1nY9I",
        "colab_type": "text"
      },
      "source": [
        "Les resultats sont un peu flous.  \n",
        "Vous pouvez essayer d'améliorer les reconstructions en augmentant la capacité de vos réseaux par exemple en rajoutant des filtres lors des couches de convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePKpsPVRnabZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "...\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2PCyFRUvIVZ",
        "colab_type": "text"
      },
      "source": [
        "Affichez vos nouveaux résultats:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbMjEqYPltgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63VLe7_wu4yf",
        "colab_type": "text"
      },
      "source": [
        "## U-net\n",
        "Nous allons maintenant nous concentrer sur une architecture particulière d'auto-encodeurs: les réseaux U-net.  \n",
        "Les réseaux U-nets sont des auto-encodeurs ayant la particularité de posséder des connections directes entre les couches de l'encodeur et les couches du décodeur.  \n",
        "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/05/Architecture-of-the-U-Net-Generator-Model.png)  \n",
        "Les couches de convolutions du décodeur vont recevoir en entrées les sorties des couches qui les précèdent ainsi que la sortie des couches de convolutions correspondantes de l'encodeur.\n",
        "\n",
        "Nous allons utiliser un réseau U-net pour recoloriser des images en noir et blanc.\n",
        "Nous utiliserons le dataset [landscape](https://github.com/ml5js/ml5-data-and-models/tree/master/datasets/images/landscapes) composé de 4000 images de paysages.  \n",
        "Commençons donc par télécharger le dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISvP-Ck8pDDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/ml5js/ml5-data-and-models/raw/master/datasets/images/landscapes/landscapes_small.zip\n",
        "!mkdir landscapes\n",
        "!unzip landscapes_small.zip -d landscapes\n",
        "!rm -r landscapes/__MACOSX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkoa7vBDBO-F",
        "colab_type": "text"
      },
      "source": [
        "Le dataset est uniquement constitué d'images en couleurs.  \n",
        "Nous allons nous même générer les images en noir et blanc à l'aide en précisiant l'option color_mode des ```\n",
        "ImageDataGenerator```.  \n",
        "Nous allons utiliser ici 4 générateurs: deux fournissant des images en couleurs et deux des images en noir et blanc.  \n",
        "Les générateurs utiliseront la même seed afin que les images en noir et blanc et en couleurs se correspondent.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSjg8hbou-fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "input_dir = 'landscapes'\n",
        "\n",
        "seed = 1\n",
        " \n",
        "color_datagen = ImageDataGenerator(rescale=1/255.0, validation_split=0.1)\n",
        "bw_datagen = ImageDataGenerator(rescale=1/255.0, validation_split=0.1)\n",
        "                                \n",
        "\n",
        "train_color_generator = color_datagen.flow_from_directory(input_dir, class_mode=None, seed=seed, subset='training', target_size=(256, 256))\n",
        "train_bw_generator = bw_datagen.flow_from_directory(input_dir, color_mode='grayscale', class_mode=None, seed=seed, subset='training', target_size=(256, 256))\n",
        "valid_color_generator = color_datagen.flow_from_directory(input_dir, class_mode=None, seed=seed, subset='validation', target_size=(256, 256))\n",
        "valid_bw_generator = bw_datagen.flow_from_directory(input_dir, color_mode='grayscale', class_mode=None, seed=seed, subset='validation', target_size=(256, 256))\n",
        "\n",
        "train_generator = (pair for pair in zip(train_bw_generator, train_color_generator))\n",
        "validation_generator = (pair for pair in zip(valid_bw_generator, valid_color_generator))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jegVQj4Nvsho",
        "colab_type": "text"
      },
      "source": [
        "Regardons un exemple du de la sortie de nos générateurs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9RPRvX6vDvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = next(train_generator)\n",
        "print(x.shape, y.shape)\n",
        "print(x.min(), x.max(), y.min(), y.max())\n",
        " \n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "idx = np.random.randint(0, len(x))\n",
        "ax1.imshow(np.squeeze(x[idx], axis=-1), cmap='gray')\n",
        "ax2.imshow(y[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vof8K98OFDlP",
        "colab_type": "text"
      },
      "source": [
        "L'un des avantages de la construction fonctionnelle en Keras est de permettre la definition de fonctions composées facilement réutilisables.  \n",
        "En voici un exemple: la fonction suivante permet de combiner une couche de convolution suivie d'une batchnormalisation en un seul appel: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hyuVYE4Ia2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "def downsampling(input, filters):\n",
        "    d = Conv2D(filters, kernel_size=4, strides=2, padding='same', activation='relu')(input)\n",
        "    d = BatchNormalization()(d)\n",
        "    return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7emFie8IvV1",
        "colab_type": "text"
      },
      "source": [
        "Codez une fonction ```upsampling(input, skip_input, filters)``` qui reçoit deux entrées:\n",
        "* Une de sa couche précédente\n",
        "* Une de la couche de la couche de l'encodeur correspondante  \n",
        "\n",
        "\n",
        "La fonction doit alors:\n",
        "* Faire un UpSampling de ```input``` suivit d'une Convolution avec fonction d'activation ReLU puis d'une Batch Normalisation.\n",
        "Utilisez un ```kernel_size=4``` un ```strides=1``` et ```padding='same'``` lors de la convolution afin que la sortie soit de la même taille que ```skip_input``` \n",
        "* [Concatener](https://keras.io/layers/merge/) la sortie de la Batch Normalisation avec ```skip_input```  (exemple: ```a = Concatenate()([a, b])```  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlG0cinNIuCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Concatenate\n",
        "\n",
        "def upsampling(layer_input, skip_input, filters):\n",
        "    ...\n",
        "    return ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wILuy5y9tRT1",
        "colab_type": "text"
      },
      "source": [
        "Vous allez maintenant définir votre réseau U-net en vous appuyant sur le shéma suivant:\n",
        "![](https://drive.google.com/uc?id=1F1uuhhRnXhV53aR1chU41Z17krRt2cuU)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEvqpDvpwIpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Image input\n",
        "d0 = Input(...)\n",
        " \n",
        "# Downsampling\n",
        "...\n",
        " \n",
        "# Upsampling\n",
        "...\n",
        "# Last upsampling\n",
        "...\n",
        "output = ...\n",
        " \n",
        "model = Model(d0, output)\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae'])\n",
        "model.fit_generator(train_generator, steps_per_epoch=100, epochs=10, validation_data=validation_generator, validation_steps=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6FL_Yadwehn",
        "colab_type": "text"
      },
      "source": [
        "Affichez maintenant plusieurs exemples du résultat de votre apprentissage:\n",
        "\n",
        "\n",
        "*   Image en noir et blanc\n",
        "*   Image en couleur d'origine\n",
        "*   Image recolorisée par le réseau\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2qhbEjJwIsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnuMFpClz-vJ",
        "colab_type": "text"
      },
      "source": [
        "Pour aller plus loin avec les auto-encodeurs:\n",
        "* Un article bien détaillé sur une amélioration des auto-encodeurs permettant de générer des nouveaux exemples: [les variationals auto-encoders](http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/):\n",
        "* Il y a quelques années un challenge Kaggle portait sur le débruitage de documents manuscrits: https://www.kaggle.com/c/denoising-dirty-documents/overview. Vous pouvez essayer d'utiliser des auto-encodeurs pour débruiter le dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtwcAfjv0s-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}